# Mock LLM configuration for token usage test
# Returns deterministic token counts in usage field
terminationGracePeriodSeconds: 3
ark:
  model:
    enabled: true
    name: test-model
    type: completions
    provider: openai
    model: gpt-4.1-mini
    pollInterval: 3s
    apiKey: mock-api-key

config:
  rules:
  - path: "/v1/models"
    method: "GET"
    response:
      status: 200
      content: |
        {
          "object": "list",
          "data": [
            {
              "id": "gpt-4",
              "object": "model",
              "created": 1687882411,
              "owned_by": "openai"
            },
            {
              "id": "gpt-4o-mini",
              "object": "model",
              "created": 1687882411,
              "owned_by": "openai"
            },
            {
              "id": "gpt-4.1",
              "object": "model",
              "created": 1687882411,
              "owned_by": "openai"
            },
            {
              "id": "gpt-5",
              "object": "model",
              "created": 1687882411,
              "owned_by": "openai"
            }
          ]
        }

  - path: "/v1/chat/completions"
    match: "@"
    response:
      status: 200
      content: |
        {
          "id": "mock-{{timestamp}}",
          "object": "chat.completion",
          "model": "{{jmes request body.model}}",
          "choices": [{
            "message": {{jmes request body.messages[-1]}},
            "finish_reason": "stop"
          }],
          "usage": {
            "prompt_tokens": 50,
            "completion_tokens": 100,
            "total_tokens": 150
          }
        }
